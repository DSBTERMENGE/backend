"""
BACKEND API - FRAMEWORK DSB
==========================
API Backend simplificada com fun√ß√µes Flask para comunica√ß√£o frontend ‚Üî backend
Vers√£o refatorada: Classes ‚Üí Fun√ß√µes simples para melhor performance e manutenibilidade
"""

# =============================================================================
# IMPORTS E DEPEND√äNCIAS
# =============================================================================

from flask import Flask, request, jsonify, send_from_directory, send_from_directory, send_from_directory
import logging
import sys
import os
from datetime import datetime, date
from decimal import Decimal
import bcrypt
import sqlite3
import data_manager
from data_manager import consultar_bd, get_view, inserir_dados, atualizar_dados, atualizar_dados_lote, excluir_dados
from debugger import flow_marker, error_catcher

# Importa debugger personalizado
from debugger import flow_marker, error_catcher, unexpected_error_catcher, _inicializar_log

# =============================================================================
# CONVERS√ÉO DE TIPOS PARA JSON (PostgreSQL)
# =============================================================================

def converter_tipos_postgresql(obj):
    """
    Converte tipos espec√≠ficos do PostgreSQL para tipos compat√≠veis com JSON
    
    - Decimal ‚Üí float (valores monet√°rios)
    - date/datetime ‚Üí string ISO YYYY-MM-DD (para <input type="date">)
    
    IMPORTANTE: Campos HTML5 <input type="date"> esperam formato ISO.
    O navegador exibe automaticamente no formato local do usu√°rio (dd/mm/yyyy no Brasil).
    """
    if isinstance(obj, Decimal):
        return float(obj)  # Decimal('3125.50') ‚Üí 3125.5
    if isinstance(obj, (date, datetime)):
        # Retorna formato ISO para compatibilidade com <input type="date">
        return obj.isoformat()  # datetime.date(2025, 10, 30) ‚Üí "2025-10-30"
    if isinstance(obj, dict):
        return {k: converter_tipos_postgresql(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [converter_tipos_postgresql(item) for item in obj]
    return obj

# =============================================================================
# VALIDA√á√ÉO CENTRALIZADA DE PAR√ÇMETROS
# =============================================================================

def validar_database_config(database_path, database_name):
    """
    Valida configura√ß√µes de banco de dados de forma centralizada
    
    ‚ö†Ô∏è IMPORTANTE: Para PostgreSQL, database_path √© string vazia ("")
    PostgreSQL n√£o usa path de arquivo - conex√£o configurada no backend (db_config.py)
    
    @param database_path: Path do banco (pode ser string vazia para PostgreSQL)
    @param database_name: Nome do banco
    @raises ValueError: Se algum par√¢metro for None (n√£o configurado)
    
    Exemplos:
        # SQLite - precisa de path
        validar_database_config("c:\\apps\\data", "financas.db")
        
        # PostgreSQL - path vazio
        validar_database_config("", "financas")
    """
    # Aceita string vazia, apenas rejeita None (n√£o configurado)
    if database_path is None:
        raise ValueError("Par√¢metro 'database_path' √© obrigat√≥rio")
    
    if not database_name:
        raise ValueError("Par√¢metro 'database_name' √© obrigat√≥rio")

# =============================================================================
# FUN√á√ÉO PARA CONFIGURAR ENDPOINTS EM QUALQUER INST√ÇNCIA FLASK
# =============================================================================

def configurar_endpoints(app):
    """
    Configura todos os endpoints da API em uma inst√¢ncia Flask fornecida
    
    @param {Flask} app - Inst√¢ncia Flask onde os endpoints ser√£o registrados
    """
    
    # Configura√ß√£o de logging
    logger = logging.getLogger(__name__)
    
    @app.route('/')
    def index():
        """
        Serve o arquivo index.html na rota raiz
        """
        return send_from_directory(app.static_folder, 'index.html')
    
    @app.route('/framework_dsb/<path:filename>')
    def serve_framework(filename):
        """
        Serve arquivos do framework DSB
        """
        # Caminho absoluto para a pasta framework_dsb
        framework_base = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        return send_from_directory(framework_base, filename)
    
    @app.route('/health', methods=['GET'])
    def health_check():
        """
        Endpoint de health check - verifica se API est√° funcionando
        
        @return {dict} - Status da API e informa√ß√µes b√°sicas
        """
        return jsonify({
            "status": "ok", 
            "app": "Framework DSB API",
            "message": "API Backend funcionando",
            "timestamp": datetime.now().isoformat()
        })
    
    @app.route('/api/login', methods=['POST'])
    def login():
        """
        Endpoint de autentica√ß√£o de usu√°rios
        Redireciona para data_manager.autoriza_login()
        """
        try:
            data = request.json
            username = data.get('username', '').strip()
            password = data.get('password', '')
            
            if not username or not password:
                return jsonify({'success': False, 'message': 'Usu√°rio e senha s√£o obrigat√≥rios'}), 400
            
            path_name = _processar_db_path_name(data)
            
            resultado = data_manager.autoriza_login(
                username=username,
                password=password,
                database_path=path_name.get('database_path'),
                database_name=path_name.get('database_name')
            )
            
            if resultado['sucesso']:
                return jsonify({'success': True, 'message': resultado['message']}), 200
            else:
                return jsonify({'success': False, 'message': resultado['message']}), 401
                
        except Exception as e:
            error_catcher("Erro no endpoint /api/login", e)
            return jsonify({'success': False, 'message': 'Erro interno no servidor'}), 500
    
    # =========================================================================
    # üíæ SISTEMA DE BACKUP AUTOM√ÅTICO
    # =========================================================================
    # 
    # üìç IMPLEMENTA√á√ÉO ATUAL:
    # - Backup salvo no PythonAnywhere: /home/davidbit/backups/
    # - Mant√©m 4 √∫ltimas c√≥pias
    # - Chamado automaticamente por cron-job.org (gr√°tis)
    # 
    # üîÑ FUTURA IMPLEMENTA√á√ÉO - GOOGLE DRIVE (quando necess√°rio):
    # 
    # MUDAN√áAS NECESS√ÅRIAS:
    # 
    # 1. Instalar depend√™ncias no requirements.txt:
    #    google-auth
    #    google-auth-oauthlib
    #    google-auth-httplib2
    #    google-api-python-client
    # 
    # 2. Criar endpoint adicional para enviar ao Google Drive:
    #    @app.route('/api/backup/sync-to-drive', methods=['POST'])
    #    def sincronizar_drive():
    #        # Autentica com Google Drive API
    #        # Upload do √∫ltimo backup para Drive
    #        # Mant√©m 4 √∫ltimas c√≥pias no Drive tamb√©m
    # 
    # 3. Ou modificar este endpoint para fazer backup duplo:
    #    - Salva no servidor (r√°pido, local)
    #    - Envia c√≥pia para Google Drive (seguran√ßa off-site)
    # 
    # 4. Configurar credenciais Google:
    #    - Criar projeto no Google Cloud Console
    #    - Habilitar Google Drive API
    #    - Baixar credentials.json
    #    - Upload para PythonAnywhere
    # 
    # C√ìDIGO EXEMPLO (descomente quando implementar):
    # 
    # from google.oauth2 import service_account
    # from googleapiclient.discovery import build
    # from googleapiclient.http import MediaFileUpload
    # 
    # def enviar_para_google_drive(arquivo_local):
    #     """Envia backup para Google Drive"""
    #     SCOPES = ['https://www.googleapis.com/auth/drive.file']
    #     SERVICE_ACCOUNT_FILE = '/home/davidbit/credentials.json'
    #     
    #     credentials = service_account.Credentials.from_service_account_file(
    #         SERVICE_ACCOUNT_FILE, scopes=SCOPES)
    #     
    #     service = build('drive', 'v3', credentials=credentials)
    #     
    #     # ID da pasta no Drive (criar pasta "Backups FinCtl" e pegar ID da URL)
    #     folder_id = 'COLE_AQUI_O_ID_DA_PASTA_DO_DRIVE'
    #     
    #     file_metadata = {
    #         'name': os.path.basename(arquivo_local),
    #         'parents': [folder_id]
    #     }
    #     
    #     media = MediaFileUpload(arquivo_local, resumable=True)
    #     
    #     file = service.files().create(
    #         body=file_metadata,
    #         media_body=media,
    #         fields='id'
    #     ).execute()
    #     
    #     return file.get('id')
    # 
    # =========================================================================
    
    @app.route('/api/backup/create', methods=['GET', 'POST'])
    def criar_backup():
        """
        Cria backup do banco de dados PostgreSQL usando pg_dump
        Endpoint chamado automaticamente por task agendada no PythonAnywhere ou manualmente
        
        Seguran√ßa: Requer token de autentica√ß√£o
        
        IMPLEMENTA√á√ÉO ATUAL: Salva no PythonAnywhere (/home/davidbit/backups/)
        Mant√©m os 4 backups mais recentes
        
        FUTURA: Descomentar c√≥digo acima para sincronizar com Google Drive
        """
        try:
            # Validar token de seguran√ßa
            token = request.args.get('token') or (request.json or {}).get('token')
            token_esperado = os.getenv('BACKUP_TOKEN', 'finctl_backup_2025_secure')
            
            if token != token_esperado:
                return jsonify({'success': False, 'message': 'Token inv√°lido'}), 401
            
            # Obter configura√ß√µes do banco
            data = request.json if request.method == 'POST' else {}
            path_name = _processar_db_path_name(data)
            
            database_name = path_name.get('database_name', 'financas')
            db_user = os.getenv('PGUSER', 'davidbit')
            
            # Criar diret√≥rio de backups no servidor
            backup_dir = '/home/davidbit/backups' if os.path.exists('/home/davidbit') else os.path.join(os.getcwd(), 'backups')
            os.makedirs(backup_dir, exist_ok=True)
            
            # Nome do arquivo de backup com timestamp
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_filename = f'financas_backup_{timestamp}.sql'
            backup_path = os.path.join(backup_dir, backup_filename)
            
            # Criar backup usando pg_dump
            import subprocess
            cmd = f'pg_dump -U {db_user} -d {database_name} -f {backup_path}'
            resultado = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            if resultado.returncode == 0 and os.path.exists(backup_path):
                tamanho = os.path.getsize(backup_path) / 1024  # KB
                
                # Comprimir o backup para economizar espa√ßo
                import gzip
                with open(backup_path, 'rb') as f_in:
                    with gzip.open(f'{backup_path}.gz', 'wb') as f_out:
                        f_out.writelines(f_in)
                os.remove(backup_path)  # Remove arquivo SQL n√£o comprimido
                backup_path = f'{backup_path}.gz'
                backup_filename = f'{backup_filename}.gz'
                tamanho_comprimido = os.path.getsize(backup_path) / 1024  # KB
                
                # Limpar backups antigos (manter √∫ltimos 4)
                # FUTURO: Quando implementar Google Drive, aumentar para manter=30 no servidor
                # e manter=4 no Google Drive (backups semanais)
                _limpar_backups_antigos(backup_dir, manter=4)
                
                # FUTURO: Descomentar quando implementar Google Drive
                # try:
                #     drive_file_id = enviar_para_google_drive(backup_path)
                #     flow_marker(f"‚úÖ Backup enviado para Google Drive: {drive_file_id}")
                # except Exception as e:
                #     error_catcher("Erro ao enviar para Google Drive (backup local OK)", e)
                
                return jsonify({
                    'success': True,
                    'arquivo': backup_filename,
                    'tamanho_original_kb': round(tamanho, 2),
                    'tamanho_comprimido_kb': round(tamanho_comprimido, 2),
                    'caminho': backup_path,
                    'timestamp': timestamp,
                    'tipo': 'PostgreSQL dump (gzip)'
                    # FUTURO: Adicionar quando implementar Drive
                    # 'google_drive_id': drive_file_id,
                    # 'google_drive_url': f'https://drive.google.com/file/d/{drive_file_id}/view'
                }), 200
            else:
                return jsonify({
                    'success': False,
                    'message': 'Erro ao criar backup',
                    'erro': resultado.stderr
                }), 500
                
        except Exception as e:
            error_catcher("Erro no endpoint /api/backup/create", e)
            return jsonify({'success': False, 'message': str(e)}), 500
    
    @app.route('/api/backup/list', methods=['GET'])
    def listar_backups():
        """Lista todos os backups dispon√≠veis"""
        try:
            # Obter diret√≥rio de backups
            data = request.args.to_dict()
            path_name = _processar_db_path_name(data)
            db_path = os.path.join(path_name.get('database_path', ''), path_name.get('database_name', 'financas.db'))
            backup_dir = os.path.join(os.path.dirname(db_path), '..', 'backups')
            
            if not os.path.exists(backup_dir):
                return jsonify({'success': True, 'backups': []}), 200
            
            # Listar arquivos de backup
            backups = []
            for arquivo in os.listdir(backup_dir):
                if arquivo.startswith('financas_backup_') and arquivo.endswith('.db'):
                    caminho_completo = os.path.join(backup_dir, arquivo)
                    stat = os.stat(caminho_completo)
                    backups.append({
                        'nome': arquivo,
                        'tamanho_kb': round(stat.st_size / 1024, 2),
                        'data_criacao': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        'timestamp': stat.st_mtime
                    })
            
            # Ordenar por data (mais recente primeiro)
            backups.sort(key=lambda x: x['timestamp'], reverse=True)
            
            return jsonify({'success': True, 'backups': backups, 'total': len(backups)}), 200
            
        except Exception as e:
            error_catcher("Erro no endpoint /api/backup/list", e)
            return jsonify({'success': False, 'message': str(e)}), 500
    
    @app.route('/api/backup/download/latest', methods=['GET'])
    def baixar_ultimo_backup():
        """Download do backup mais recente"""
        try:
            from flask import send_file
            
            # Obter diret√≥rio de backups
            data = request.args.to_dict()
            path_name = _processar_db_path_name(data)
            db_path = os.path.join(path_name.get('database_path', ''), path_name.get('database_name', 'financas.db'))
            backup_dir = os.path.join(os.path.dirname(db_path), '..', 'backups')
            
            if not os.path.exists(backup_dir):
                return jsonify({'success': False, 'message': 'Nenhum backup encontrado'}), 404
            
            # Encontrar backup mais recente
            backups = [f for f in os.listdir(backup_dir) if f.startswith('financas_backup_') and f.endswith('.db')]
            
            if not backups:
                return jsonify({'success': False, 'message': 'Nenhum backup encontrado'}), 404
            
            backups.sort(reverse=True)  # Ordem alfab√©tica = ordem cronol√≥gica
            ultimo_backup = os.path.join(backup_dir, backups[0])
            
            return send_file(
                ultimo_backup,
                mimetype='application/x-sqlite3',
                as_attachment=True,
                download_name=backups[0]
            )
            
        except Exception as e:
            error_catcher("Erro no endpoint /api/backup/download/latest", e)
            return jsonify({'success': False, 'message': str(e)}), 500
    
    @app.route('/api/backup/download/<filename>', methods=['GET'])
    def baixar_backup_especifico(filename):
        """Download de backup espec√≠fico"""
        try:
            from flask import send_file
            
            # Validar nome do arquivo (seguran√ßa)
            if not filename.startswith('financas_backup_') or not filename.endswith('.db'):
                return jsonify({'success': False, 'message': 'Nome de arquivo inv√°lido'}), 400
            
            # Obter diret√≥rio de backups
            data = request.args.to_dict()
            path_name = _processar_db_path_name(data)
            db_path = os.path.join(path_name.get('database_path', ''), path_name.get('database_name', 'financas.db'))
            backup_dir = os.path.join(os.path.dirname(db_path), '..', 'backups')
            backup_path = os.path.join(backup_dir, filename)
            
            if not os.path.exists(backup_path):
                return jsonify({'success': False, 'message': 'Backup n√£o encontrado'}), 404
            
            return send_file(
                backup_path,
                mimetype='application/x-sqlite3',
                as_attachment=True,
                download_name=filename
            )
            
        except Exception as e:
            error_catcher("Erro no endpoint /api/backup/download", e)
            return jsonify({'success': False, 'message': str(e)}), 500

    @app.route('/processar_extratos_pdf', methods=['POST'])
    def processar_extratos_pdf():
        """
        Endpoint para processar extratos PDF e extrair despesas
        Delega toda valida√ß√£o para o orquestrador de valida√ß√£o
        
        Executa o processo completo:
        1. Valida√ß√£o de arquivos e banco de dados (orquestrador)
        2. Extra√ß√£o de dados dos PDFs
        3. Classifica√ß√£o das despesas
        4. Salvamento no banco de dados
        
        @return {dict} - Resultado do processamento com status e mensagem
        """
        flow_marker("IN√çCIO endpoint /processar_extratos_pdf")
        _inicializar_log()  # Limpa o log anterior
        
        try:
            # Adicionar o path do extrator ao sys.path
            extrator_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'extratorDePDF')
            if extrator_path not in sys.path:
                sys.path.append(extrator_path)
            
            # Imports diretos com path absoluto
            try:
                import importlib.util
                
                # Carregar orquestrador_validacao
                spec_validacao = importlib.util.spec_from_file_location(
                    "orquestrador_validacao", 
                    os.path.join(extrator_path, "orquestrador_validacao.py")
                )
                orquestrador_validacao = importlib.util.module_from_spec(spec_validacao)
                spec_validacao.loader.exec_module(orquestrador_validacao)
                
                # Carregar orquestrador_extracao  
                spec_extracao = importlib.util.spec_from_file_location(
                    "orquestrador_extracao",
                    os.path.join(extrator_path, "orquestrador_extracao.py")
                )
                orquestrador_extracao = importlib.util.module_from_spec(spec_extracao)
                spec_extracao.loader.exec_module(orquestrador_extracao)
                
                # Extrair as fun√ß√µes necess√°rias
                executar_validacao_completa = orquestrador_validacao.executar_validacao_completa
                processar_e_salvar_extratos = orquestrador_extracao.processar_e_salvar_extratos
                
            except (ImportError, AttributeError, FileNotFoundError) as e:
                flow_marker(f"Erro ao importar m√≥dulos do extrator: {str(e)}")
                return jsonify({
                    "sucesso": False,
                    "msg": f"M√≥dulo extrator n√£o encontrado: {str(e)}"
                }), 500
            
            # FASE 1: Valida√ß√£o completa (orquestrador faz todas as verifica√ß√µes)
            sucesso_validacao, dados_validados = executar_validacao_completa()
            
            if not sucesso_validacao:
                flow_marker(f"Valida√ß√£o falhou: {dados_validados}")
                return jsonify({
                    "sucesso": False,
                    "msg": f"Erro na valida√ß√£o: {dados_validados}. Verifique o arquivo log_de_erros.md para detalhes."
                }), 400
            
            flow_marker(f"Valida√ß√£o bem-sucedida. Dados validados: {dados_validados}")
            
            # FASE 2: Processamento e salvamento
            flow_marker("Iniciando extra√ß√£o e salvamento dos extratos")
            sucesso_extracao, mensagem_extracao = processar_e_salvar_extratos(dados_validados)
            
            if sucesso_extracao:
                flow_marker(f"Processo conclu√≠do com sucesso: {mensagem_extracao}")
                return jsonify({
                    "sucesso": True,
                    "mensagem": mensagem_extracao
                })
            else:
                flow_marker(f"Erro na extra√ß√£o: {mensagem_extracao}")
                return jsonify({
                    "sucesso": False,
                    "mensagem": f"{mensagem_extracao}\n\nVerifique o arquivo log_de_erros.md para detalhes."
                }), 500
                
        except ImportError as e:
            error_msg = f"Erro ao importar m√≥dulos de extra√ß√£o: {str(e)}"
            error_catcher(error_msg, e)
            return jsonify({
                "sucesso": False,
                "msg": "Erro nos m√≥dulos de extra√ß√£o. Verifique o arquivo log_de_erros.md para detalhes."
            }), 500
            
        except Exception as e:
            error_msg = f"Erro inesperado durante processamento: {str(e)}"
            error_catcher(error_msg, e)
            return jsonify({
                "sucesso": False,
                "msg": "Erro inesperado no processamento. Verifique o arquivo log_de_erros.md para detalhes."
            }), 500

    @app.route('/consultar_dados_db', methods=['POST'])
    def consultar_dados_db():
        """
        Endpoint para consultar dados de views prontas para popular formul√°rios
        
        REGRA IMPORTANTE: Este endpoint deve ser usado APENAS com views prontas
        que foram criadas especificamente para uso em determinados formul√°rios.
        
        N√ÉO usar consultas diretas em tabelas - sempre usar views dedicadas.
        
        @param {string} view - Nome da view pronta (ex: vw_grupos, vw_lancamentos)
        @param {string} database_path - Caminho do banco de dados
        @param {string} database_name - Nome do arquivo do banco
        @param {string} database_host - Host do banco (se remoto)
        @return {dict} - Dicion√°rio de dados para popular formul√°rio
        """
        flow_marker("IN√çCIO endpoint /consultar_dados_db")
        
        try:
            # Valida√ß√£o de request usando fun√ß√£o auxiliar
            dados_request, erro = _validar_request_json()
            if erro:
                return erro
            
            flow_marker("Dados recebidos no endpoint", dados_request)
            
            # Valida se view foi fornecida
            nome_view = dados_request.get('view', '')
            if not nome_view:
                return jsonify({
                    "dados": [],
                    "mensagem": "Nome da view n√£o fornecido"
                }), 400
            
            # Valida campos solicitados
            campos_solicitados = dados_request.get('campos', ['Todos'])
            if not campos_solicitados or campos_solicitados == []:
                return jsonify({
                    "dados": [],
                    "mensagem": "Nenhum campo informado"
                }), 400
            
            flow_marker(f"Consultando view: {nome_view} com campos: {campos_solicitados}")
            
            # Processa configura√ß√µes
            path_name = _processar_db_path_name(dados_request)
            
            # Extrai filtros da requisi√ß√£o
            filtros = dados_request.get('filtros', '')
            
            # Executa consulta na view usando fun√ß√£o direta
            resultado = consultar_bd(nome_view, campos_solicitados, database_path=path_name.get('database_path'), database_name=path_name.get('database_name'), filtros=filtros)
            
            # ‚úÖ CONVERTE Decimal ‚Üí float, date ‚Üí ISO (YYYY-MM-DD) para <input type="date">
            resultado_convertido = converter_tipos_postgresql(resultado)
            
            # Prepara resposta padronizada
            resposta = {
                "dados": resultado_convertido if resultado_convertido else [],
                "mensagem": "sucesso"
            }
            
            flow_marker(f"Consulta executada - View: {nome_view}, Registros: {len(resultado) if resultado else 0}")
            
            # Rastreamento do envio da resposta
            flow_marker(f"‚úÖ ENVIANDO RESPOSTA AO FRONTEND: {len(resultado) if resultado else 0} registros")
            flow_marker(f"üì§ ESTRUTURA DA RESPOSTA: {resposta}")
            
            return jsonify(resposta)
            
        except Exception as e:
            return _erro_padronizado("/consultar_dados_db", e)

    @app.route('/update_data_db', methods=['POST'])
    def update_data_db():
        """
        Endpoint para atualizar dados existentes
        
        @param {dict} dados_para_update - Dados para atualiza√ß√£o contendo:
            - tabela: nome da tabela
            - campos: lista de campos  
            - dados_a_atualizar: dados atuais do registro
            - dados_form_out: novos dados para atualiza√ß√£o
            - database_path: caminho do banco
            - database_name: nome do banco
        @return {dict} - Resultado da opera√ß√£o de atualiza√ß√£o
        """
        flow_marker("IN√çCIO endpoint /update_data_db")
        
        try:
            # Valida√ß√£o de request usando fun√ß√£o auxiliar
            dados_request, erro = _validar_request_json()
            if erro:
                return erro
            
            flow_marker("Dados recebidos no endpoint", dados_request)
            
            # Valida se tabela_alvo foi fornecida
            tabela = dados_request.get('tabela_alvo', '')
            if not tabela:
                return jsonify({
                    "dados": [],
                    "mensagem": "Nome da tabela_alvo n√£o fornecido"
                }), 400
            
            flow_marker(f"Atualizando tabela: {tabela}")
            
            # Processa configura√ß√µes
            path_name = _processar_db_path_name(dados_request)
            
            # Extrai par√¢metros adicionais do payload
            tabela_alvo = dados_request.get('tabela_alvo')
            campos_obrigatorios = dados_request.get('campos_obrigatorios')
            filtros = dados_request.get('filtros', '')
            
            # Executa opera√ß√£o de update usando fun√ß√£o direta
            dados_a_atualizar = dados_request.get('dados', {})
            resultado = atualizar_dados(tabela, dados_a_atualizar, path_name.get('database_path'), path_name.get('database_name'), tabela_alvo, campos_obrigatorios)
            
            flow_marker(f"Update executado - Tabela: {tabela}")
            flow_marker("üîç RESULTADO da fun√ß√£o atualizar_dados", resultado)
            
            # ===============================================================
            # ESTRAT√âGIA DE SINCRONIZA√á√ÉO INTELIGENTE (UPDATE):
            # Ap√≥s atualiza√ß√£o bem-sucedida, consultamos novamente a view para
            # retornar o array completo atualizado e ordenado.
            # Isso evita "tremor" na interface e mant√©m navega√ß√£o fluida,
            # especialmente quando campos ordenados s√£o alterados.
            # ===============================================================
            
            if resultado.get('sucesso'):
                flow_marker('üîÑ Consultando dados atualizados ap√≥s update')
                
                # Consulta dados atualizados aplicando filtros (se houver)
                consulta_atualizada = consultar_bd(
                    f"{tabela_alvo}_view", 
                    ['Todos'], 
                    database_path=path_name.get('database_path'), 
                    database_name=path_name.get('database_name'),
                    filtros=filtros if filtros else None
                )
                
                flow_marker('üìä Dados atualizados consultados', {
                    'view': f"{tabela_alvo}_view",
                    'filtros_aplicados': filtros if filtros else 'Nenhum',
                    'total_registros': len(consulta_atualizada.get('dados', [])) if consulta_atualizada and consulta_atualizada.get('dados') else 0
                })
                
                # ‚úÖ CONVERTE Decimal ‚Üí float, date ‚Üí dd/mm/yyyy ANTES de enviar JSON
                dados_convertidos = converter_tipos_postgresql(consulta_atualizada.get('dados', [])) if consulta_atualizada else []
                
                # Resposta enriquecida com dados atualizados
                resultado_final = {
                    "sucesso": True,
                    "mensagem": resultado.get('mensagem', 'Registro atualizado com sucesso'),
                    "dados_atualizados": dados_convertidos,
                    "total_registros": len(dados_convertidos)
                }
                
                flow_marker('‚úÖ Resposta completa com dados atualizados (UPDATE)', {
                    'total_registros': resultado_final['total_registros']
                })
                
                return jsonify(resultado_final)
            
            return jsonify(resultado)
            
        except Exception as e:
            return _erro_padronizado("/update_data_db", e)

    @app.route('/verificar_dependencias_delete', methods=['POST'])
    def verificar_dependencias_delete_endpoint():
        """
        Endpoint para verificar se h√° registros dependentes antes de deletar
        
        @param {dict} payload - Dados da requisi√ß√£o contendo:
            - tabela_alvo (str): Nome da tabela onde est√° o registro
            - id_campo (str): Nome do campo chave prim√°ria
            - id_valor (int|str): Valor da chave prim√°ria
            - database_name (str): Nome do banco
        
        @return {dict} - {'tem_dependencias': bool, 'quantidade': int, 'detalhes': list}
        """
        try:
            dados = request.get_json()
            
            tabela_alvo = dados.get('tabela_alvo')
            id_campo = dados.get('id_campo')
            id_valor = dados.get('id_valor')
            database_name = dados.get('database_name')
            
            # Valida√ß√µes
            if not all([tabela_alvo, id_campo, id_valor, database_name]):
                return jsonify({
                    'erro': 'Par√¢metros obrigat√≥rios: tabela_alvo, id_campo, id_valor, database_name'
                }), 400
            
            # Chama fun√ß√£o de verifica√ß√£o
            resultado = verificar_dependencias_delete(
                tabela_alvo=tabela_alvo,
                id_campo=id_campo,
                id_valor=id_valor,
                database_name=database_name
            )
            
            return jsonify(resultado)
            
        except Exception as e:
            return _erro_padronizado("/verificar_dependencias_delete", e)

    @app.route('/atualizar_lote', methods=['POST'])
    def atualizar_lote():
        """
        Endpoint para atualizar m√∫ltiplos registros em lote (opera√ß√£o em massa)
        FUN√á√ÉO GEN√âRICA: Pode ser usada para qualquer tabela do sistema
        
        Performance: 1 requisi√ß√£o HTTP + loop interno de UPDATEs + 1 COMMIT
        Muito mais r√°pido que N requisi√ß√µes individuais
        
        @param {dict} payload - Dados da requisi√ß√£o contendo:
            - tabela_alvo (str): Nome da tabela para UPDATE (ex: 'despesas', 'produtos')
            - dados_lote (list[dict]): Array de objetos com dados para atualizar
                                       Ex: [{'iddespesa': 1234, 'idgrupo': 3, 'idsubgrupo': 5}, ...]
            - pk_field (str): Nome do campo chave prim√°ria (ex: 'iddespesa', 'idproduto')
            - campos_permitidos (list): Lista de campos permitidos para atualiza√ß√£o (seguran√ßa)
                                       Ex: ['idgrupo', 'idsubgrupo']
            - database_path (str): Caminho do banco (opcional, usa config padr√£o)
            - database_name (str): Nome do banco (opcional, usa config padr√£o)
        
        @return {dict} - Resultado com estat√≠sticas:
                        {
                            "sucesso": True/False,
                            "total_processados": 1000,
                            "atualizados": 950,
                            "erros": 50,
                            "erros_detalhes": [{...}]
                        }
        
        @example Requisi√ß√£o:
            POST /atualizar_lote
            {
                "tabela_alvo": "despesas",
                "dados_lote": [
                    {"iddespesa": 1234, "idgrupo": 3, "idsubgrupo": 5},
                    {"iddespesa": 1235, "idgrupo": 2, "idsubgrupo": 8}
                ],
                "pk_field": "iddespesa",
                "campos_permitidos": ["idgrupo", "idsubgrupo"],
                "database_path": "C:/Apps/data",
                "database_name": "financas.db"
            }
        """
        flow_marker("IN√çCIO endpoint /atualizar_lote")
        
        try:
            # Valida√ß√£o de request usando fun√ß√£o auxiliar
            dados_request, erro = _validar_request_json()
            if erro:
                return erro
            
            flow_marker("Dados recebidos no endpoint /atualizar_lote", {
                "tabela_alvo": dados_request.get('tabela_alvo'),
                "total_registros": len(dados_request.get('dados_lote', [])),
                "pk_field": dados_request.get('pk_field')
            })
            
            # =================================================================
            # VALIDA√á√ÉO DE PAR√ÇMETROS OBRIGAT√ìRIOS
            # =================================================================
            
            tabela_alvo = dados_request.get('tabela_alvo')
            if not tabela_alvo:
                flow_marker("‚ùå Erro: tabela_alvo n√£o fornecida")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'tabela_alvo' n√£o fornecido"
                }), 400
            
            dados_lote = dados_request.get('dados_lote')
            if not dados_lote or not isinstance(dados_lote, list) or len(dados_lote) == 0:
                flow_marker("‚ùå Erro: dados_lote inv√°lido")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'dados_lote' deve ser um array n√£o vazio"
                }), 400
            
            pk_field = dados_request.get('pk_field')
            if not pk_field:
                flow_marker("‚ùå Erro: pk_field n√£o fornecido")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'pk_field' n√£o fornecido"
                }), 400
            
            # Par√¢metros opcionais
            campos_permitidos = dados_request.get('campos_permitidos')  # Pode ser None
            
            # Processa configura√ß√µes de banco de dados
            path_name = _processar_db_path_name(dados_request)
            database_path = path_name.get('database_path')
            database_name = path_name.get('database_name')
            
            flow_marker(f"Par√¢metros validados - Tabela: {tabela_alvo}, PK: {pk_field}, Registros: {len(dados_lote)}")
            
            # =================================================================
            # EXECUTA ATUALIZA√á√ÉO EM LOTE
            # =================================================================
            
            resultado = atualizar_dados_lote(
                tabela_alvo=tabela_alvo,
                dados_lote=dados_lote,
                pk_field=pk_field,
                database_path=database_path,
                database_name=database_name,
                campos_permitidos=campos_permitidos
            )
            
            flow_marker("Atualiza√ß√£o em lote conclu√≠da", {
                "sucesso": resultado.get('sucesso'),
                "total_processados": resultado.get('total_processados', 0),
                "atualizados": resultado.get('atualizados', 0),
                "erros": resultado.get('erros', 0)
            })
            
            # =================================================================
            # RETORNA RESULTADO
            # =================================================================
            
            if resultado.get('sucesso'):
                flow_marker("‚úÖ Atualiza√ß√£o em lote bem-sucedida")
                return jsonify(resultado), 200
            else:
                flow_marker("‚ùå Atualiza√ß√£o em lote com erro")
                return jsonify(resultado), 500
            
        except Exception as e:
            flow_marker(f"‚ùå EXCE√á√ÉO no endpoint /atualizar_lote: {str(e)}")
            return _erro_padronizado("/atualizar_lote", e)

    @app.route('/incluir_reg_novo_db', methods=['POST'])
    def incluir_reg_novo_db():
        """
        Endpoint para incluir novos registros
        
        @param {dict} dados_novo_registro - Dados do novo registro
        @return {dict} - Resultado da opera√ß√£o de inclus√£o
        """
        try:
            flow_marker('üîÑ IN√çCIO endpoint /incluir_reg_novo_db')
            
            dados_request = request.get_json()
            flow_marker('üìã Dados recebidos no endpoint', dados_request)
            
            # Extrai par√¢metros da requisi√ß√£o
            tabela_alvo = dados_request.get('tabela_alvo')
            dados_form_in = dados_request.get('dados', {})
            database_path = dados_request.get('database_path')
            database_name = dados_request.get('database_name')
            campos_obrigatorios = dados_request.get('campos_obrigatorios', [])
            filtros = dados_request.get('filtros', '')
            
            # Constr√≥i caminho completo do banco
            database_file = os.path.join(database_path, database_name)
            
            flow_marker('üîß Par√¢metros extra√≠dos', {
                'tabela_alvo': tabela_alvo,
                'database_file': database_file,
                'campos_para_inserir': list(dados_form_in.keys()),
                'filtros': filtros
            })
            
            # Chama data_manager para inserir dados
            resultado = data_manager.inserir_dados(
                tabela=tabela_alvo,
                dados_form_in=dados_form_in,
                database_path=database_path,
                database_name=database_name,
                tabela_alvo=tabela_alvo,
                campos_obrigatorios=campos_obrigatorios
            )
            
            flow_marker('üì§ Resultado da inser√ß√£o', resultado)
            
            if resultado.get('sucesso'):
                # ===============================================================
                # ESTRAT√âGIA DE SINCRONIZA√á√ÉO INTELIGENTE:
                # Ap√≥s inser√ß√£o bem-sucedida, consultamos novamente a view para
                # retornar o array completo atualizado e ordenado.
                # Isso evita "tremor" na interface e mant√©m navega√ß√£o fluida,
                # pois o frontend substitui dadosDisponiveis e recalcula reg_num
                # automaticamente atrav√©s de find() da nova PK.
                # ===============================================================
                
                flow_marker('üîÑ Consultando dados atualizados ap√≥s inser√ß√£o')
                
                # Consulta dados atualizados aplicando filtros (se houver)
                consulta_atualizada = consultar_bd(
                    f"{tabela_alvo}_view", 
                    ['Todos'], 
                    database_path=database_path, 
                    database_name=database_name,
                    filtros=filtros if filtros else None
                )
            
                flow_marker('üìä Dados atualizados consultados', {
                    'view': f"{tabela_alvo}_view",
                    'filtros_aplicados': filtros if filtros else 'Nenhum',
                    'total_registros': len(consulta_atualizada.get('dados', [])) if consulta_atualizada and consulta_atualizada.get('dados') else 0
                })
                
                # ‚úÖ CONVERTE Decimal ‚Üí float, date ‚Üí dd/mm/yyyy ANTES de enviar JSON
                dados_convertidos = converter_tipos_postgresql(consulta_atualizada.get('dados', [])) if consulta_atualizada else []
                
                resposta = {
                    "sucesso": True,
                    "mensagem": resultado.get('mensagem', 'Registro inserido com sucesso'),
                    "dados_atualizados": dados_convertidos,
                    "total_registros": len(dados_convertidos)
                }
                flow_marker('‚úÖ Resposta completa com dados atualizados', {
                    'total_registros': resposta['total_registros']
                })
                return jsonify(resposta)
            else:
                resposta = {
                    "sucesso": False,
                    "mensagem": resultado.get('mensagem', 'Erro na inser√ß√£o')
                }
                flow_marker('‚ùå Resposta de erro', resposta)
                return jsonify(resposta), 400
            
        except Exception as e:
            logger.error(f"Erro em incluir_reg_novo_db: {e}")
            flow_marker('üí• Erro cr√≠tico no endpoint', str(e))
            return jsonify({"sucesso": False, "mensagem": f"Erro: {str(e)}"}), 500

    @app.route('/delete_reg', methods=['POST'])
    def delete_reg():
        """
        Endpoint para excluir registros existentes
        
        @param {dict} dados_para_delete - Dados para exclus√£o contendo:
            - tabela_alvo: nome da tabela
            - pk_para_excluir: chave prim√°ria do registro a excluir
            - database_path: caminho do banco
            - database_name: nome do banco
            - forcar: (opcional) True para for√ßar exclus√£o ignorando depend√™ncias
        @return {dict} - Resultado da opera√ß√£o de exclus√£o com dados atualizados
        """
        flow_marker('üîÑ IN√çCIO endpoint /delete_reg')
        
        try:
            # Valida√ß√£o de request usando fun√ß√£o auxiliar
            dados_request, erro = _validar_request_json()
            if erro:
                return erro
            
            flow_marker('üìã Dados recebidos no endpoint', dados_request)
            
            # Valida se tabela_alvo foi fornecida
            tabela_alvo = dados_request.get('tabela_alvo', '')
            if not tabela_alvo:
                return jsonify({
                    "sucesso": False,
                    "mensagem": "Nome da tabela_alvo n√£o fornecido"
                }), 400
            
            # Valida se pk_para_excluir foi fornecida
            pk_para_excluir = dados_request.get('pk_para_excluir')
            if not pk_para_excluir:
                return jsonify({
                    "sucesso": False,
                    "mensagem": "Chave prim√°ria para exclus√£o n√£o fornecida"
                }), 400
            
            # Extrai flag forcar (default: False)
            forcar = dados_request.get('forcar', False)
            
            flow_marker(f'üóëÔ∏è Excluindo registro da tabela: {tabela_alvo}, PK: {pk_para_excluir}, For√ßar: {forcar}')
            
            # Processa configura√ß√µes
            database_path = dados_request.get('database_path', '')
            database_name = dados_request.get('database_name', '')
            
            # Monta caminho completo do banco
            database_file = os.path.join(database_path, database_name)
            flow_marker('üîß Par√¢metros extra√≠dos', {
                'tabela_alvo': tabela_alvo,
                'database_file': database_file,
                'pk_para_excluir': pk_para_excluir,
                'forcar': forcar
            })
            
            # Executa opera√ß√£o de exclus√£o usando fun√ß√£o direta (COM PAR√ÇMETRO FORCAR)
            resultado = excluir_dados(tabela_alvo, pk_para_excluir, database_path, database_name, tabela_alvo, forcar)
            
            flow_marker('üì§ Resultado da exclus√£o', resultado)
            
            # ===============================================================
            # ESTRAT√âGIA DE SINCRONIZA√á√ÉO INTELIGENTE (DELETE):
            # Ap√≥s exclus√£o bem-sucedida, consultamos novamente a view para
            # retornar o array completo atualizado e ordenado.
            # Isso evita "tremor" na interface e mant√©m navega√ß√£o fluida,
            # reposicionando automaticamente ap√≥s remo√ß√£o do registro.
            # ===============================================================
            
            if resultado.get('sucesso'):
                flow_marker('üîÑ Consultando dados atualizados ap√≥s exclus√£o')
                
                # Consulta dados atualizados com par√¢metros corretos
                consulta_atualizada = consultar_bd(f"{tabela_alvo}_view", ['Todos'], database_path=database_path, database_name=database_name)
                
                flow_marker('üìä Dados atualizados consultados', {
                    'view': f"{tabela_alvo}_view",
                    'total_registros': len(consulta_atualizada.get('dados', [])) if consulta_atualizada and consulta_atualizada.get('dados') else 0
                })
                
                # ‚úÖ CONVERTE Decimal ‚Üí float, date ‚Üí dd/mm/yyyy ANTES de enviar JSON
                dados_convertidos = converter_tipos_postgresql(consulta_atualizada.get('dados', [])) if consulta_atualizada else []
                
                resposta = {
                    "sucesso": True,
                    "mensagem": resultado.get('mensagem', 'Registro exclu√≠do com sucesso'),
                    "dados_atualizados": dados_convertidos,
                    "total_registros": len(dados_convertidos)
                }
                flow_marker('‚úÖ Resposta completa com dados atualizados (DELETE)', {
                    'total_registros': resposta['total_registros']
                })
                return jsonify(resposta)
            else:
                resposta = {
                    "sucesso": False,
                    "mensagem": resultado.get('mensagem', 'Erro na exclus√£o')
                }
                flow_marker('‚ùå Resposta de erro', resposta)
                return jsonify(resposta), 400
            
        except Exception as e:
            logger.error(f"Erro em delete_reg: {e}")
            flow_marker('üí• Erro cr√≠tico no endpoint', str(e))
            return jsonify({"sucesso": False, "mensagem": f"Erro: {str(e)}"}), 500

    @app.route('/executar_sql', methods=['POST'])
    def executar_sql_endpoint():
        """
        Endpoint para executar SQL direto no banco de dados
        
        Permite envio de consultas SQL personalizadas do frontend.
        Retorna dados estruturados para SELECT ou resultado de opera√ß√£o para DDL/DML.
        
        @param {dict} request_data - Dados da requisi√ß√£o
        @param {str} request_data.sql - Comando SQL a executar
        @param {str} request_data.database_path - Caminho do banco
        @param {str} request_data.database_name - Nome do banco
        
        @return {dict} - Resultado estruturado:
        Para SELECT: {"sucesso": True, "dados": [{"campo": "valor"}], "mensagem": "..."}
        Para DDL/DML: {"sucesso": True, "registros_afetados": N, "mensagem": "..."}
        Para erro: {"sucesso": False, "erro": "..."}
        """
        flow_marker("IN√çCIO endpoint /executar_sql")
        
        try:
            # Valida√ß√£o do request JSON
            dados_request, erro_response = _validar_request_json()
            if erro_response:
                return erro_response
            
            # Valida√ß√£o de campos obrigat√≥rios
            sql = dados_request.get('sql', '').strip()
            if not sql:
                flow_marker('‚ùå SQL n√£o fornecido')
                return jsonify({
                    "sucesso": False,
                    "erro": "SQL n√£o fornecido"
                }), 400
            
            # Extra√ß√£o de par√¢metros obrigat√≥rios
            database_path = dados_request.get('database_path')
            database_name = dados_request.get('database_name')
            
            # Valida√ß√£o centralizada
            try:
                validar_database_config(database_path, database_name)
            except ValueError as e:
                flow_marker(f'‚ùå {str(e)}')
                return jsonify({
                    "sucesso": False,
                    "erro": str(e)
                }), 400
            
            flow_marker(f"üìù SQL recebido: {sql[:100]}...")
            flow_marker(f"üíæ Database: {database_name} em {database_path}")
            
            # Importa e executa a fun√ß√£o do data_manager
            from data_manager import executar_sql
            resultado = executar_sql(sql, database_path, database_name)
            
            # ‚úÖ CONVERTE Decimal ‚Üí float ANTES de enviar JSON
            if resultado.get('sucesso') and resultado.get('dados'):
                resultado['dados'] = converter_tipos_postgresql(resultado['dados'])
            
            # Loga o resultado para diagn√≥stico
            flow_marker(f"üìä RESULTADO da query SQL: {resultado}")
            
            # Retorna resultado estruturado
            if resultado.get('sucesso'):
                flow_marker('‚úÖ SQL executado com sucesso')
                return jsonify(resultado)
            else:
                flow_marker(f'‚ùå Erro na execu√ß√£o SQL: {resultado.get("erro")}')
                return jsonify(resultado), 400
                
        except Exception as e:
            logger.error(f"Erro em executar_sql_endpoint: {e}")
            flow_marker('üí• Erro cr√≠tico no endpoint executar_sql', str(e))
            return jsonify({
                "sucesso": False,
                "erro": f"Erro interno: {str(e)}"
            }), 500

    @app.route('/analise_abc', methods=['POST'])
    def analise_abc_endpoint():
        """
        Endpoint para an√°lise ABC de despesas
        
        Retorna curva ABC de despesas individuais, por grupos e dados para gr√°fico pizza
        conforme filtros fornecidos (ano, m√™s, institui√ß√£o)
        
        @param {dict} request_data - Dados da requisi√ß√£o:
            - tipo_analise: 'despesas_individuais' | 'por_grupos' | 'grafico_pizza'
            - ano: Ano para filtro (ex: '2025')
            - mes: M√™s para filtro (ex: 'MAR')
            - instituicao: Institui√ß√£o financeira (ex: 'MASTERCARD') ou null para todas
            - database_path: Caminho do banco (opcional)
            - database_name: Nome do banco (opcional)
        
        @return {dict} - Resultado da an√°lise ABC estruturado
        """
        flow_marker("IN√çCIO endpoint /analise_abc")
        
        try:
            # Valida√ß√£o do request JSON
            dados_request, erro_response = _validar_request_json()
            if erro_response:
                return erro_response
            
            # Extra√ß√£o de par√¢metros
            tipo_analise = dados_request.get('tipo_analise', '').lower()
            ano = dados_request.get('ano')
            mes = dados_request.get('mes')
            instituicao = dados_request.get('instituicao')
            database_path = dados_request.get('database_path')
            database_name = dados_request.get('database_name')
            
            # Valida√ß√µes
            if not tipo_analise:
                flow_marker('‚ùå tipo_analise n√£o fornecido')
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'tipo_analise' √© obrigat√≥rio"
                }), 400
            
            if tipo_analise not in ['despesas_individuais', 'por_grupos', 'grafico_pizza']:
                flow_marker(f'‚ùå tipo_analise inv√°lido: {tipo_analise}')
                return jsonify({
                    "sucesso": False,
                    "erro": "tipo_analise deve ser: 'despesas_individuais', 'por_grupos' ou 'grafico_pizza'"
                }), 400
            
            if not ano or not mes:
                flow_marker('‚ùå Filtros ano/mes n√£o fornecidos')
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metros 'ano' e 'mes' s√£o obrigat√≥rios"
                }), 400
            
            flow_marker(f"üìä An√°lise ABC solicitada: {tipo_analise}")
            flow_marker(f"üìÖ Filtros: {ano}/{mes}, Institui√ß√£o: {instituicao or 'TODAS'}")
            
            # Importar fun√ß√µes do data_analysis
            import data_analysis
            
            # Montar filtro data_extrato
            data_extrato = f"{mes}_{ano}"
            
            # Construir filtros
            filtros = {'data_extrato': data_extrato}
            if instituicao:
                filtros['instituicao'] = instituicao
            
            # =============================================================
            # AN√ÅLISE 1: CURVA ABC - DESPESAS INDIVIDUAIS
            # =============================================================
            if tipo_analise == 'despesas_individuais':
                flow_marker("Calculando Curva ABC - Despesas Individuais")
                
                resultado = data_analysis.calcular_curva_abc(
                    view_name='despesas_view',
                    campo_descricao='descricao',
                    campo_valor='valor',
                    filtros=filtros,
                    database_path=database_path,
                    database_name=database_name,
                    limite_a=80.0,
                    limite_b=95.0
                )
                
                if resultado['sucesso']:
                    flow_marker(f"‚úÖ Curva ABC calculada: {len(resultado['dados'])} despesas")
                    return jsonify(resultado)
                else:
                    flow_marker(f"‚ùå Erro ao calcular curva ABC: {resultado.get('erro')}")
                    return jsonify(resultado), 400
            
            # =============================================================
            # AN√ÅLISE 2: CURVA ABC - POR GRUPOS
            # =============================================================
            elif tipo_analise == 'por_grupos':
                flow_marker("Calculando Curva ABC - Por Grupos")
                
                resultado = data_analysis.calcular_curva_abc(
                    view_name='despesas_view_01',
                    campo_descricao='grupo',
                    campo_valor='valor',
                    filtros=filtros,
                    database_path=database_path,
                    database_name=database_name,
                    limite_a=80.0,
                    limite_b=95.0
                )
                
                if resultado['sucesso']:
                    flow_marker(f"‚úÖ Curva ABC por grupos calculada: {len(resultado['dados'])} grupos")
                    return jsonify(resultado)
                else:
                    flow_marker(f"‚ùå Erro ao calcular curva ABC por grupos: {resultado.get('erro')}")
                    return jsonify(resultado), 400
            
            # =============================================================
            # AN√ÅLISE 3: DADOS PARA GR√ÅFICO PIZZA
            # =============================================================
            elif tipo_analise == 'grafico_pizza':
                flow_marker("Preparando dados para gr√°fico pizza")
                
                # Primeiro calcular curva ABC por grupos
                curva_grupos = data_analysis.calcular_curva_abc(
                    view_name='despesas_view_01',
                    campo_descricao='grupo',
                    campo_valor='valor',
                    filtros=filtros,
                    database_path=database_path,
                    database_name=database_name,
                    limite_a=80.0,
                    limite_b=95.0
                )
                
                if not curva_grupos['sucesso']:
                    flow_marker(f"‚ùå Erro ao calcular curva ABC para pizza: {curva_grupos.get('erro')}")
                    return jsonify(curva_grupos), 400
                
                # Preparar dados para pizza (threshold 2%)
                resultado = data_analysis.preparar_dados_grafico_pizza(
                    dados_curva_abc=curva_grupos['dados'],
                    campo_label='descricao',  # calcular_curva_abc renomeia para 'descricao'
                    campo_valor='valor_total',
                    campo_percentual='percentual',
                    threshold=2.0
                )
                
                if resultado['sucesso']:
                    flow_marker(f"‚úÖ Dados pizza preparados: {len(resultado['labels'])} fatias")
                    return jsonify(resultado)
                else:
                    flow_marker(f"‚ùå Erro ao preparar dados pizza: {resultado.get('erro')}")
                    return jsonify(resultado), 400
                
        except ImportError as e:
            logger.error(f"Erro ao importar data_analysis: {e}")
            flow_marker('üí• M√≥dulo data_analysis n√£o encontrado', str(e))
            return jsonify({
                "sucesso": False,
                "erro": f"M√≥dulo de an√°lise n√£o dispon√≠vel: {str(e)}"
            }), 500
            
        except Exception as e:
            logger.error(f"Erro em analise_abc_endpoint: {e}")
            flow_marker('üí• Erro cr√≠tico no endpoint analise_abc', str(e))
            return jsonify({
                "sucesso": False,
                "erro": f"Erro interno: {str(e)}"
            }), 500

    # =============================================================================
    #                    ENDPOINT: EVOLU√á√ÉO MENSAL DE DESPESAS (12M)
    # =============================================================================
    
    @app.route('/despesas_12m', methods=['POST'])
    def despesas_12m_endpoint():
        """
        ‚úÖ ENDPOINT GEN√âRICO - Retorna evolu√ß√£o mensal em formato de matriz pivotada
        
        FILOSOFIA: Backend N√ÉO decide view, campos ou filtros - apenas EXECUTA o que recebe
        
        REQUEST JSON (TUDO vem do RELAT√ìRIO):
        {
            "ano_referencia": 2024,           // OBRIGAT√ìRIO - Ano para an√°lise
            "view_name": "despesas_view",     // OBRIGAT√ìRIO - View a consultar
            "campo_descricao": "grupo",       // OBRIGAT√ìRIO - Campo para linhas
            "campo_valor": "valor",           // OBRIGAT√ìRIO - Campo para agrega√ß√£o
            "campo_ano": "ano",               // OPCIONAL - Nome do campo ano (padr√£o: 'ano')
            "campo_mes": "mes",               // OPCIONAL - Nome do campo m√™s (padr√£o: 'mes')
            "filtros": {                      // OPCIONAL - Filtros din√¢micos
                "instituicao": "Itau",
                "tipo": "Despesa"
            },
            "database_path": "c:\\...",       // OBRIGAT√ìRIO - Caminho do banco
            "database_name": "financas.db"    // OBRIGAT√ìRIO - Nome do arquivo .db
        }
        
        RESPONSE JSON:
        {
            "sucesso": true,
            "colunas": ["JAN", "FEV", "MAR", ..., "TOTAL"],
            "linhas": [
                {
                    "descricao": "Alimenta√ß√£o",
                    "JAN": 1200.00,
                    "FEV": 1350.00,
                    ...
                    "TOTAL": 15000.00
                },
                ...
            ],
            "resumo": {
                "ano": 2024,
                "meses_com_dados": 12,
                "total_descricoes": 5,
                "total_geral": 27500.00,
                "ano_corrente": false
            },
            "criterios": {...}
        }
        """
        try:
            flow_marker("IN√çCIO endpoint /despesas_12m")
            
            # =============================================================
            # VALIDA√á√ÉO DE REQUEST
            # =============================================================
            
            if not request.is_json:
                flow_marker("‚ùå Request n√£o √© JSON")
                return jsonify({
                    "sucesso": False,
                    "erro": "Content-Type deve ser application/json"
                }), 400
            
            dados = request.get_json()
            flow_marker(f"üì¶ Dados recebidos: {dados}")
            
            # ‚úÖ EXTRAIR TODOS OS PAR√ÇMETROS DO PAYLOAD (frontend define tudo)
            view_name = dados.get('view_name')
            campo_Agrupamento = dados.get('campo_Agrupamento')
            campo_Pivot = dados.get('campo_Pivot')
            campo_valor = dados.get('campo_valor')
            numColunasPivot = dados.get('numColunasPivot', 12)
            database_path = dados.get('database_path')
            database_name = dados.get('database_name')
            
            # Validar par√¢metros obrigat√≥rios
            if not view_name:
                flow_marker("‚ùå Par√¢metro 'view_name' n√£o fornecido")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'view_name' √© obrigat√≥rio"
                }), 400
            
            if not campo_Agrupamento:
                flow_marker("‚ùå Par√¢metro 'campo_Agrupamento' n√£o fornecido")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'campo_Agrupamento' √© obrigat√≥rio"
                }), 400
            
            if not campo_Pivot:
                flow_marker("‚ùå Par√¢metro 'campo_Pivot' n√£o fornecido")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'campo_Pivot' √© obrigat√≥rio"
                }), 400
            
            if not campo_valor:
                flow_marker("‚ùå Par√¢metro 'campo_valor' n√£o fornecido")
                return jsonify({
                    "sucesso": False,
                    "erro": "Par√¢metro 'campo_valor' √© obrigat√≥rio"
                }), 400
            
            # Valida√ß√£o centralizada de database_path e database_name
            try:
                validar_database_config(database_path, database_name)
            except ValueError as e:
                flow_marker(f"‚ùå {str(e)}")
                return jsonify({
                    "sucesso": False,
                    "erro": str(e)
                }), 400
            
            # =============================================================
            # CHAMAR FUN√á√ÉO DE AN√ÅLISE COM PAR√ÇMETROS DO PAYLOAD
            # =============================================================
            
            flow_marker(f"üìä Calculando tabela pivot:")
            flow_marker(f"   - View: {view_name}")
            flow_marker(f"   - Campo agrupamento: {campo_Agrupamento}")
            flow_marker(f"   - Campo pivot: {campo_Pivot}")
            flow_marker(f"   - Campo valor: {campo_valor}")
            flow_marker(f"   - Num colunas pivot: {numColunasPivot}")
            
            import data_analysis
            
            resultado = data_analysis.calcular_tabela_pivot(
                view_name=view_name,
                campo_Agrupamento=campo_Agrupamento,
                campo_Pivot=campo_Pivot,
                campo_valor=campo_valor,
                numColunasPivot=numColunasPivot,
                database_path=database_path,
                database_name=database_name
            )
            
            # =============================================================
            # RETORNAR RESULTADO
            # =============================================================
            
            if resultado['success']:
                num_grupos = len(resultado['labels']) - 1  # -1 para excluir TOTAL GERAL
                num_colunas = len(resultado['colunas'])
                flow_marker(f"‚úÖ Tabela pivot calculada: {num_grupos} grupos √ó {num_colunas} colunas")
                return jsonify(resultado)
            else:
                flow_marker(f"‚ùå Erro ao calcular tabela pivot: {resultado.get('erro')}")
                return jsonify(resultado), 400
        
        except ImportError as e:
            logger.error(f"Erro ao importar m√≥dulo de an√°lise: {e}")
            flow_marker('üí• M√≥dulo data_analysis n√£o encontrado', str(e))
            return jsonify({
                "success": False,
                "erro": f"M√≥dulo de an√°lise n√£o dispon√≠vel: {str(e)}"
            }), 500
            
        except Exception as e:
            logger.error(f"Erro em despesas_12m_endpoint: {e}")
            flow_marker('üí• Erro cr√≠tico no endpoint despesas_12m', str(e))
            return jsonify({
                "success": False,
                "erro": f"Erro interno: {str(e)}"
            }), 500

   
# =============================================================================
#                           VALIDA√á√ïES
# =============================================================================

def _validar_request_json():
    """
    Valida se o request cont√©m JSON v√°lido
    
    @return {tuple} - (dados_request, erro_response) 
    """
    dados_request = request.get_json()

    if not dados_request:
        flow_marker("ERRO: Dados n√£o fornecidos")
        erro = jsonify({
            "dados": [],
            "mensagem": "Dados n√£o fornecidos"
        }), 400
        return None, erro
    
    # Retorna dados v√°lidos sem erro
    return dados_request, None

# =============================================================================
#                         FUN√á√ïES AUXILIARES
# =============================================================================

def _processar_db_path_name(dados_request):
    """
    Organiza os dados de configura√ß√£o do database em um dicion√°rio
    @param {dict} dados_request - Dados da requisi√ß√£o
    @return {dict} - Configura√ß√µes do database processadas
    """
    return {
        'database_path': dados_request.get('database_path', ''),
        'database_name': dados_request.get('database_name', ''),
        'database_host': dados_request.get('database_host', '')
    }

def _limpar_backups_antigos(backup_dir, manter=4):
    """
    Remove backups antigos, mantendo apenas os N mais recentes
    
    @param {str} backup_dir - Diret√≥rio com os backups
    @param {int} manter - Quantidade de backups a manter
    """
    try:
        # Listar todos os backups (PostgreSQL dumps comprimidos)
        backups = []
        for arquivo in os.listdir(backup_dir):
            if arquivo.startswith('financas_backup_') and arquivo.endswith('.sql.gz'):
                caminho = os.path.join(backup_dir, arquivo)
                backups.append((arquivo, os.path.getmtime(caminho)))
        
        # Ordenar por data (mais recente primeiro)
        backups.sort(key=lambda x: x[1], reverse=True)
        
        # Deletar excedentes
        if len(backups) > manter:
            for arquivo, _ in backups[manter:]:
                caminho = os.path.join(backup_dir, arquivo)
                os.remove(caminho)
                flow_marker(f"üóëÔ∏è Backup antigo removido: {arquivo}")
                
    except Exception as e:
        error_catcher("Erro ao limpar backups antigos", e)

def _erro_padronizado(endpoint_nome, erro):
    """
    Gera resposta de erro padronizada
    
    @param {string} endpoint_nome - Nome do endpoint
    @param {Exception} erro - Objeto de erro
    @return {tuple} - Response JSON e c√≥digo HTTP
    """
    error_catcher(f"Erro no endpoint {endpoint_nome}", erro)
    return jsonify({
        "dados": [],
        "mensagem": f"Erro interno: {str(erro)}"
    }), 500

